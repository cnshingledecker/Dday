{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527621ca",
   "metadata": {},
   "source": [
    "### How it works:\n",
    "\n",
    "Here the data is imported from the csv and analytics files into pandas dataframes so they can be plotted in another notebook. The dataframes are saved using ```pandas.DataFrame.to_pickle('file_name.pkl')```. They can then be loaded into the plotting notebook using ```pandas.DataFrame.read_pickle('file_name.pkl')```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34321531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce0ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['be-', 'bO', 'bO2', 'bO2-', 'bO2*', 'bO2+', 'bO3', 'bO3-', 'bO3*', 'bO3+', 'bO-', 'bO*', 'bO+', \\\n",
    "                'e-', 'G0', 'G-', 'ge-', \\\n",
    "                'gO', 'gO2', 'gO2-', 'gO2*', 'gO2+', 'gO3', 'gO3-', 'gO3*', 'gO3+', 'gO-', 'gO*', 'gO+', \\\n",
    "                'O', 'O2', 'O2-', 'O2+', 'O3', 'O3-', 'O3+', 'O-', 'O+', \\\n",
    "                'total_ice_O', 'total_ice_O2', 'total_ice_O3']\n",
    "bulk_list = ['be-', 'bO', 'bO2', 'bO2-', 'bO2*', 'bO2+', 'bO3', 'bO3-', 'bO3*', 'bO3+', 'bO-', 'bO*', 'bO+']\n",
    "bulk_list_woions = ['bO','bO*', 'bO2', 'bO2*', 'bO3', 'bO3*']\n",
    "all_list_woions = ['bO', 'bO2', 'bO3', 'gO', 'gO2', 'gO3']\n",
    "bulk_list_2 = ['be-', 'bO', 'bO2', 'bO2-', 'bO2+', 'bO3', 'bO3-', 'bO3+', 'bO-', 'bO+'] #The suprathermal species disappeared from my folder\n",
    "bulk_ion_list = ['be-', 'bO2-', 'bO2+', 'bO3-', 'bO3+', 'bO-', 'bO+']\n",
    "ion_list = ['bO+', 'bO2+', 'bO3+'] # for testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bd54f",
   "metadata": {},
   "source": [
    "## Define filepath\n",
    "\n",
    "This is the filepath from the current directory to the directory where your data is stored. This directory should contain the subdirectories: csv, analytics, pickle_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09230a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'w_ions/22_02_07_fit'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf69088",
   "metadata": {},
   "source": [
    "## Importing csv files\n",
    "\n",
    "Imports csv files for all species in ``wk_list`` into a pandas dataframe. (Also does a small amount of data analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265cf9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Fluence           be-            bO       bO2          bO2-  \\\n",
      "0   0.000039  7.982000e-12  7.471000e-14  0.004559  7.432000e-18   \n",
      "1   0.000048  9.851000e-12  7.471000e-14  0.004559  9.408000e-18   \n",
      "2   0.000059  1.216000e-11  7.471000e-14  0.004559  3.260000e-17   \n",
      "3   0.000073  1.500000e-11  7.471000e-14  0.004559  6.252000e-17   \n",
      "4   0.000090  1.851000e-11  7.471000e-14  0.004559  9.946000e-17   \n",
      "5   0.000111  2.285000e-11  7.471000e-14  0.004559  1.450000e-16   \n",
      "6   0.000138  2.819000e-11  7.471000e-14  0.004559  2.013000e-16   \n",
      "7   0.000170  3.479000e-11  7.471000e-14  0.004559  2.707000e-16   \n",
      "8   0.000209  4.293000e-11  7.471000e-14  0.004559  3.563000e-16   \n",
      "9   0.000258  5.298000e-11  7.471000e-14  0.004559  4.621000e-16   \n",
      "10  0.000319  6.538000e-11  7.471000e-14  0.004559  5.925000e-16   \n",
      "11  0.000394  8.069000e-11  7.471000e-14  0.004559  7.535000e-16   \n",
      "12  0.000486  9.957000e-11  7.471000e-14  0.004559  9.854000e-16   \n",
      "13  0.000599  1.229000e-10  7.471000e-14  0.004559  2.901000e-15   \n",
      "14  0.000740  1.516000e-10  7.471000e-14  0.004559  5.266000e-15   \n",
      "15  0.000913  1.871000e-10  7.471000e-14  0.004559  8.183000e-15   \n",
      "16  0.001126  2.309000e-10  7.471000e-14  0.004559  1.178000e-14   \n",
      "17  0.001390  2.850000e-10  7.471000e-14  0.004559  1.623000e-14   \n",
      "18  0.001715  3.517000e-10  7.471000e-14  0.004559  2.171000e-14   \n",
      "19  0.002117  4.340000e-10  7.471000e-14  0.004559  2.848000e-14   \n",
      "20  0.002612  5.356000e-10  7.471000e-14  0.004559  3.683000e-14   \n",
      "21  0.003224  6.609000e-10  7.471000e-14  0.004559  4.713000e-14   \n",
      "22  0.003978  8.156000e-10  7.471000e-14  0.004559  6.280000e-14   \n",
      "23  0.004910  1.007000e-09  7.472000e-14  0.004559  9.218000e-14   \n",
      "24  0.006059  1.242000e-09  7.472000e-14  0.004559  1.284000e-13   \n",
      "\n",
      "            bO2+           bO3          bO3-          bO3+           bO-  \\\n",
      "0   7.982000e-12  3.092000e-10  1.145000e-16  3.115000e-18  2.934000e-10   \n",
      "1   9.851000e-12  3.816000e-10  1.449000e-16  3.943000e-18  3.620000e-10   \n",
      "2   1.216000e-11  4.710000e-10  5.020000e-16  1.366000e-17  4.467000e-10   \n",
      "3   1.500000e-11  5.812000e-10  9.629000e-16  2.621000e-17  5.513000e-10   \n",
      "4   1.851000e-11  7.173000e-10  1.532000e-15  4.168000e-17  6.804000e-10   \n",
      "5   2.285000e-11  8.852000e-10  2.234000e-15  6.079000e-17  8.396000e-10   \n",
      "6   2.820000e-11  1.092000e-09  3.100000e-15  8.436000e-17  1.036000e-09   \n",
      "7   3.480000e-11  1.348000e-09  4.169000e-15  1.135000e-16  1.279000e-09   \n",
      "8   4.294000e-11  1.664000e-09  5.488000e-15  1.494000e-16  1.578000e-09   \n",
      "9   5.299000e-11  2.053000e-09  7.116000e-15  1.937000e-16  1.947000e-09   \n",
      "10  6.539000e-11  2.534000e-09  9.125000e-15  2.483000e-16  2.403000e-09   \n",
      "11  8.070000e-11  3.127000e-09  1.160000e-14  3.158000e-16  2.965000e-09   \n",
      "12  9.959000e-11  3.859000e-09  1.518000e-14  4.130000e-16  3.659000e-09   \n",
      "13  1.229000e-10  4.762000e-09  4.468000e-14  1.217000e-15  4.516000e-09   \n",
      "14  1.517000e-10  5.876000e-09  8.109000e-14  2.208000e-15  5.573000e-09   \n",
      "15  1.873000e-10  7.252000e-09  1.260000e-13  3.432000e-15  6.877000e-09   \n",
      "16  2.311000e-10  8.949000e-09  1.815000e-13  4.943000e-15  8.487000e-09   \n",
      "17  2.852000e-10  1.104000e-08  2.499000e-13  6.807000e-15  1.047000e-08   \n",
      "18  3.520000e-10  1.363000e-08  3.343000e-13  9.107000e-15  1.292000e-08   \n",
      "19  4.344000e-10  1.682000e-08  4.385000e-13  1.195000e-14  1.595000e-08   \n",
      "20  5.362000e-10  2.075000e-08  5.671000e-13  1.545000e-14  1.968000e-08   \n",
      "21  6.617000e-10  2.561000e-08  7.258000e-13  1.977000e-14  2.429000e-08   \n",
      "22  8.166000e-10  3.161000e-08  9.670000e-13  2.634000e-14  2.997000e-08   \n",
      "23  1.008000e-09  3.900000e-08  1.419000e-12  3.868000e-14  3.699000e-08   \n",
      "24  1.244000e-09  4.813000e-08  1.978000e-12  5.389000e-14  4.565000e-08   \n",
      "\n",
      "             bO+  Ion volume density  Total volume density   Percent Ion  \n",
      "0   2.934000e-10        6.027641e-10              0.004559  1.322141e-07  \n",
      "1   3.620000e-10        7.437022e-10              0.004559  1.631283e-07  \n",
      "2   4.467000e-10        9.177205e-10              0.004559  2.012986e-07  \n",
      "3   5.513000e-10        1.132601e-09              0.004559  2.484318e-07  \n",
      "4   6.804000e-10        1.397822e-09              0.004559  3.066069e-07  \n",
      "5   8.396000e-10        1.724902e-09              0.004559  3.783508e-07  \n",
      "6   1.036000e-09        2.128393e-09              0.004559  4.668550e-07  \n",
      "7   1.279000e-09        2.627595e-09              0.004559  5.763528e-07  \n",
      "8   1.578000e-09        3.241876e-09              0.004559  7.110929e-07  \n",
      "9   1.947000e-09        3.999978e-09              0.004559  8.773794e-07  \n",
      "10  2.403000e-09        4.936780e-09              0.004559  1.082863e-06  \n",
      "11  2.965000e-09        6.091403e-09              0.004559  1.336124e-06  \n",
      "12  3.659000e-09        7.517177e-09              0.004559  1.648861e-06  \n",
      "13  4.516000e-09        9.277849e-09              0.004559  2.035056e-06  \n",
      "14  5.573000e-09        1.144939e-08              0.004559  2.511372e-06  \n",
      "15  6.877000e-09        1.412854e-08              0.004559  3.099029e-06  \n",
      "16  8.487000e-09        1.743620e-08              0.004559  3.824544e-06  \n",
      "17  1.047000e-08        2.151047e-08              0.004559  4.718210e-06  \n",
      "18  1.292000e-08        2.654407e-08              0.004559  5.822292e-06  \n",
      "19  1.595000e-08        3.276888e-08              0.004559  7.187656e-06  \n",
      "20  1.968000e-08        4.043242e-08              0.004559  8.868585e-06  \n",
      "21  2.429000e-08        4.990339e-08              0.004559  1.094595e-05  \n",
      "22  2.997000e-08        6.157326e-08              0.004559  1.350559e-05  \n",
      "23  3.699000e-08        7.599655e-08              0.004559  1.666915e-05  \n",
      "24  4.565000e-08        9.378816e-08              0.004559  2.057145e-05  \n"
     ]
    }
   ],
   "source": [
    "## For new code outputs\n",
    "\n",
    "# Change to the list you want the data for\n",
    "wk_lst = bulk_list_2\n",
    "\n",
    "# Rewrite csv file in order to modify the header, must be done to then read into a dataframe. I used code from  https://stackoverflow.com/questions/16306819/python-edit-csv-headers \n",
    "i = 0\n",
    "while i < len(wk_lst) :\n",
    "    inputFileName = version + \"/csv/\" + wk_lst[i] + \".csv\"\n",
    "    outputFileName = os.path.splitext(inputFileName)[0] + \"_modified.csv\"\n",
    "    \n",
    "    with open(inputFileName, newline='') as inFile, open(outputFileName, 'w', newline='') as outfile:\n",
    "        r = csv.reader(inFile)\n",
    "        w = csv.writer(outfile)\n",
    "        \n",
    "        next(r, None)  # skip the first row from the reader, the old header\n",
    "        # write new header\n",
    "        w.writerow(['Fluence', wk_lst[i]])\n",
    "        \n",
    "        # copy the rest\n",
    "        for row in r:\n",
    "            w.writerow(row)\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "# read and merge data\n",
    "i=0\n",
    "\n",
    "while i < len(wk_lst) :\n",
    "    csv = pd.read_csv(version + \"/csv/\" + wk_lst[i] + \"_modified.csv\")\n",
    "    if i == 0:\n",
    "        merged_data = csv\n",
    "    else:\n",
    "        merged_data = merged_data.merge(csv, on=[\"Fluence\"])\n",
    "    i += 1\n",
    "    \n",
    "# Some data analysis\n",
    "merged_data['Ion volume density'] = merged_data[bulk_ion_list].sum(axis=1)\n",
    "merged_data['Total volume density'] = merged_data[bulk_list_2].sum(axis=1)\n",
    "merged_data['Percent Ion'] = merged_data['Ion volume density']/merged_data['Total volume density']\n",
    "\n",
    "# Save dataframe\n",
    "merged_data.to_pickle(version + '/pickle_dataframes/csv_dataframe.pkl')\n",
    "print(merged_data.head(n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6461f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Time      bO           bO2      bO3       gO       gO2  gO3  \\\n",
      "0   0.000039  0.1471  4.559000e+09    408.3   0.0817  912000.0  0.0   \n",
      "1   0.000048  0.1471  4.559000e+09    503.9   0.1008  912000.0  0.0   \n",
      "2   0.000059  0.1471  4.559000e+09    621.8   0.1244  912000.0  0.0   \n",
      "3   0.000073  0.1471  4.559000e+09    767.4   0.1535  912000.0  0.0   \n",
      "4   0.000090  0.1471  4.559000e+09    947.1   0.1895  912000.0  0.0   \n",
      "5   0.000111  0.1471  4.559000e+09   1169.0   0.2338  912000.0  0.0   \n",
      "6   0.000138  0.1471  4.559000e+09   1442.0   0.2886  912000.0  0.0   \n",
      "7   0.000170  0.1471  4.559000e+09   1780.0   0.3561  912000.0  0.0   \n",
      "8   0.000209  0.1471  4.559000e+09   2197.0   0.4395  912000.0  0.0   \n",
      "9   0.000258  0.1471  4.559000e+09   2711.0   0.5423  912000.0  0.0   \n",
      "10  0.000319  0.1471  4.559000e+09   3345.0   0.6692  912000.0  0.0   \n",
      "11  0.000394  0.1471  4.559000e+09   4128.0   0.8259  912000.0  0.0   \n",
      "12  0.000486  0.1471  4.559000e+09   5095.0   1.0190  912000.0  0.0   \n",
      "13  0.000599  0.1471  4.559000e+09   6287.0   1.2580  912000.0  0.0   \n",
      "14  0.000740  0.1471  4.559000e+09   7759.0   1.5520  912000.0  0.0   \n",
      "15  0.000913  0.1471  4.559000e+09   9575.0   1.9150  912000.0  0.0   \n",
      "16  0.001126  0.1471  4.559000e+09  11820.0   2.3640  912000.0  0.0   \n",
      "17  0.001390  0.1471  4.559000e+09  14580.0   2.9170  912000.0  0.0   \n",
      "18  0.001715  0.1471  4.559000e+09  17990.0   3.6000  912000.0  0.0   \n",
      "19  0.002117  0.1471  4.559000e+09  22210.0   4.4420  912000.0  0.0   \n",
      "20  0.002612  0.1471  4.559000e+09  27400.0   5.4820  912000.0  0.0   \n",
      "21  0.003224  0.1471  4.559000e+09  33820.0   6.7650  912000.0  0.0   \n",
      "22  0.003978  0.1471  4.559000e+09  41730.0   8.3490  912000.0  0.0   \n",
      "23  0.004910  0.1471  4.559000e+09  51500.0  10.3000  912000.0  0.0   \n",
      "24  0.006059  0.1471  4.559000e+09  63550.0  12.7100  912000.0  0.0   \n",
      "\n",
      "         Fluence      total_O2  total_O3  \n",
      "0   9.070690e+09  4.559912e+09     408.3  \n",
      "1   1.119565e+10  4.559912e+09     503.9  \n",
      "2   1.381457e+10  4.559912e+09     621.8  \n",
      "3   1.704861e+10  4.559912e+09     767.4  \n",
      "4   2.103990e+10  4.559912e+09     947.1  \n",
      "5   2.595620e+10  4.559912e+09    1169.0  \n",
      "6   3.203750e+10  4.559912e+09    1442.0  \n",
      "7   3.954010e+10  4.559912e+09    1780.0  \n",
      "8   4.879020e+10  4.559912e+09    2197.0  \n",
      "9   6.020720e+10  4.559912e+09    2711.0  \n",
      "10  7.430370e+10  4.559912e+09    3345.0  \n",
      "11  9.170880e+10  4.559912e+09    4128.0  \n",
      "12  1.131681e+11  4.559912e+09    5095.0  \n",
      "13  1.396602e+11  4.559912e+09    6287.0  \n",
      "14  1.723501e+11  4.559912e+09    7759.0  \n",
      "15  2.126824e+11  4.559912e+09    9575.0  \n",
      "16  2.623580e+11  4.559912e+09   11820.0  \n",
      "17  3.238700e+11  4.559912e+09   14580.0  \n",
      "18  3.995950e+11  4.559912e+09   17990.0  \n",
      "19  4.932610e+11  4.559912e+09   22210.0  \n",
      "20  6.085960e+11  4.559912e+09   27400.0  \n",
      "21  7.511920e+11  4.559912e+09   33820.0  \n",
      "22  9.268740e+11  4.559912e+09   41730.0  \n",
      "23  1.144030e+12  4.559912e+09   51500.0  \n",
      "24  1.411747e+12  4.559912e+09   63550.0  \n"
     ]
    }
   ],
   "source": [
    "## For old code outputs\n",
    "## This is only for the version of the code from the Mullikin paper. \n",
    "\n",
    "# import csv\n",
    "# import os\n",
    "\n",
    "# # Change to the list you want the data for\n",
    "# wk_lst = all_list_woions\n",
    "# #version = 'wo_ions/old_output'\n",
    "\n",
    "# # Rewrite csv file in order to modify the header, must be done to then read into a dataframe. I used code from  https://stackoverflow.com/questions/16306819/python-edit-csv-headers \n",
    "# i = 0\n",
    "# while i < len(wk_lst) :\n",
    "#     inputFileName = version + \"/csv/\" + wk_lst[i] + \".csv\"\n",
    "#     outputFileName = os.path.splitext(inputFileName)[0] + \"_modified.csv\"\n",
    "    \n",
    "#     with open(inputFileName, newline='') as inFile, open(outputFileName, 'w', newline='') as outfile:\n",
    "#         r = csv.reader(inFile)\n",
    "#         w = csv.writer(outfile)\n",
    "        \n",
    "#         next(r, None)  # skip the first row from the reader, the old header\n",
    "#         # write new header\n",
    "#         w.writerow(['Time', wk_lst[i]])\n",
    "        \n",
    "#         # copy the rest\n",
    "#         for row in r:\n",
    "#             w.writerow(row)\n",
    "        \n",
    "#     i += 1\n",
    "\n",
    "# # read and merge data\n",
    "# i=0\n",
    "\n",
    "# while i < len(wk_lst) :\n",
    "#     csv = pd.read_csv(version + \"/csv/\" + wk_lst[i] + \"_modified.csv\")\n",
    "#     if i == 0:\n",
    "#         merged_data = csv\n",
    "#     else:\n",
    "#         merged_data = merged_data.merge(csv, on=[\"Time\"])\n",
    "#     i += 1\n",
    "    \n",
    "# flux = 2.33e14\n",
    "\n",
    "# merged_data['Fluence'] = merged_data['Time'] * flux\n",
    "# merged_data['total_O2'] = merged_data['bO2'] + merged_data['gO2']\n",
    "# merged_data['total_O3'] = merged_data['bO3'] + merged_data['gO3']\n",
    "    \n",
    "# # Save dataframe\n",
    "# merged_data.to_pickle(version + '/pickle_dataframes/csv_dataframe.pkl')\n",
    "# print(merged_data.head(n=25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34024c",
   "metadata": {},
   "source": [
    "## Importing and formatting analytics files\n",
    "\n",
    "``ana_list`` and ``num_rxn`` must be updated based on the analytics files. ``num_rxn`` should store the number of reactions in the analytics file for the corresponding species in `ana_list``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b0154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be-\n",
      "    Fluence  177.0  69.0  81.0  61.0  71.0  72.0\n",
      "0  0.000091  100.0  -0.0  -0.0  -0.0  -0.0  -0.0\n",
      "1  0.000112  100.0  -0.0  -0.0  -0.0  -0.0  -0.0\n",
      "2  0.000138  100.0  -0.0  -0.0  -0.0  -0.0  -0.0\n",
      "3  0.000170  100.0  -0.0  -0.0  -0.0  -0.0  -0.0\n",
      "4  0.000210  100.0  -0.0  -0.0  -0.0  -0.0  -0.0\n",
      "bO\n",
      "    Fluence    156    169  158   64  181\n",
      "0  0.000091 -66.57  31.44  1.7  0.0  0.0\n",
      "1  0.000112 -66.57  31.44  1.7  0.0  0.0\n",
      "2  0.000138 -66.57  31.44  1.7  0.0  0.0\n",
      "3  0.000170 -66.57  31.44  1.7  0.0  0.0\n",
      "4  0.000210 -66.57  31.44  1.7  0.0  0.0\n",
      "bO-\n",
      "    Fluence    171   70  183   82   62   63   73   74   85\n",
      "0  0.000091  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "1  0.000112  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "2  0.000138  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "3  0.000170  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "4  0.000210  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "bO+\n",
      "    Fluence    171   64  179   62   63   67   68   65   66\n",
      "0  0.000091  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "1  0.000112  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "2  0.000138  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "3  0.000170  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "4  0.000210  100.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "bO2\n",
      "    Fluence   156    171    173    169    159  181   82   83\n",
      "0  0.000091 -25.7 -24.27 -24.27 -12.14  12.09  0.0  0.0  0.0\n",
      "1  0.000112 -25.7 -24.27 -24.27 -12.14  12.09  0.0  0.0  0.0\n",
      "2  0.000138 -25.7 -24.27 -24.27 -12.14  12.09  0.0  0.0  0.0\n",
      "3  0.000170 -25.7 -24.27 -24.27 -12.14  12.09  0.0  0.0  0.0\n",
      "4  0.000210 -25.7 -24.27 -24.27 -12.14  12.09  0.0  0.0  0.0\n",
      "bO2-\n",
      "    Fluence    179    69   82   83   65   66   76   77\n",
      "0  0.000091  91.73  8.27  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "1  0.000112  91.73  8.27  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "2  0.000138  91.73  8.27  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "3  0.000170  91.73  8.27  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "4  0.000210  91.73  8.27  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "bO2+\n",
      "    Fluence    177   64  183   75   73   74   76   77\n",
      "0  0.000091  100.0  0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "1  0.000112  100.0  0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "2  0.000138  100.0  0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "3  0.000170  100.0  0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "4  0.000210  100.0  0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "bO3\n",
      "    Fluence    160  179  181  183  185   82   83\n",
      "0  0.000091  100.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "1  0.000112  100.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "2  0.000138  100.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "3  0.000170  100.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "4  0.000210  100.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "bO3-\n",
      "    Fluence     70   85   67   68   83   78   79   80\n",
      "0  0.000091  100.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0\n",
      "1  0.000112  100.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0\n",
      "2  0.000138  100.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0\n",
      "3  0.000170  100.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0\n",
      "4  0.000210  100.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0\n",
      "bO3+\n",
      "    Fluence     75   84   88   89\n",
      "0  0.000091  100.0 -0.0 -0.0 -0.0\n",
      "1  0.000112  100.0 -0.0 -0.0 -0.0\n",
      "2  0.000138  100.0 -0.0 -0.0 -0.0\n",
      "3  0.000170  100.0 -0.0 -0.0 -0.0\n",
      "4  0.000210  100.0 -0.0 -0.0 -0.0\n"
     ]
    }
   ],
   "source": [
    "# Defining values needed to read the analytics files\n",
    "# with ions\n",
    "ana_list = ['be-', 'bO', 'bO-', 'bO+', 'bO2', 'bO2-', 'bO2+', 'bO3', 'bO3-', 'bO3+']\n",
    "num_rxn = [9, 24, 13, 11, 36, 14, 15, 15, 13, 15]\n",
    "\n",
    "# #w/o ions\n",
    "# ana_list = ['bO', 'bO2', 'bO3']\n",
    "# num_rxn = [19, 24, 8]\n",
    "\n",
    "\n",
    "# Defining the fixed width columns\n",
    "flu_col_lbl = ['NA', 'Fluence']\n",
    "flu_specs = [(0,22), (22,-1)]\n",
    "column_label = ['Index', 'Rxn', 'R1', 'R2', 'P1', 'P2', 'P3', 'D1', 'D2', 'D3', 'D4', 'D5']\n",
    "col_specs = [(0, 4), (4, 10), (10, 20), (20, 30), (30, 40), (40, 50), (50,80), (80, 91), (91, 98), (98, 103), (103, 116), (116, -1)]\n",
    "\n",
    "# A comand that returns true if the row is not a fluence row\n",
    "def logic1(index):\n",
    "    if (index+1) % flu_row == 0:\n",
    "       return False\n",
    "    return True\n",
    "# A comand that returns true if the row is a fluence row\n",
    "def logic2(index):\n",
    "    if (index+1) % flu_row == 0:\n",
    "       return True\n",
    "    return False\n",
    "\n",
    "i=0\n",
    "while i < len(ana_list) :\n",
    "    filename = version + \"/analytics/analytics_\" + ana_list[i]\n",
    "    flu_row = num_rxn[i] + 1\n",
    "    \n",
    "    # Read only the fluence rows\n",
    "    temp_df = pd.read_fwf(filename, \\\n",
    "                          skiprows= lambda x: logic1(x), \\\n",
    "                          names=flu_col_lbl, \\\n",
    "                          colspecs=flu_specs \\\n",
    "                         )\n",
    "    # Duplicate each row by number of reactions\n",
    "    temp_df_2 = pd.concat([temp_df] * num_rxn[i], ignore_index = True)\n",
    "    # Sort so all x repeats are sequestial\n",
    "    flu_df = temp_df_2.sort_values(by=['Fluence'], ignore_index = True)\n",
    "    \n",
    "    # Read only the non-fluence rows \n",
    "    df_rxn = pd.read_fwf(filename, \\\n",
    "                         skiprows = lambda x: logic2(x), \\\n",
    "                         colspecs=col_specs, \\\n",
    "                         names=column_label \\\n",
    "                        )\n",
    "    # Merge the dataframes and delete unnecessary columns\n",
    "    merged_df = flu_df.join(df_rxn)\n",
    "    del merged_df['NA']\n",
    "    del merged_df['Index']\n",
    "    del merged_df['R1']\n",
    "    del merged_df['R2']\n",
    "    del merged_df['P1']\n",
    "    del merged_df['P2']\n",
    "    del merged_df['P3']\n",
    "    del merged_df['D1']\n",
    "    del merged_df['D3']\n",
    "    del merged_df['D4']\n",
    "    del merged_df['D5']\n",
    "    \n",
    "    j=0\n",
    "    plot_rxn_list = []\n",
    "    \n",
    "    while j < num_rxn[i]:\n",
    "        # Get reaction number from dataframe\n",
    "        rxn_num = merged_df['Rxn'].values[j] \n",
    "        plot_rxn_list.append(rxn_num)\n",
    "        # Create temporary df of only one reaction\n",
    "        temp_df = merged_df[merged_df['Rxn'] == rxn_num]\n",
    "        # Rename D2 to the reaction number\n",
    "        temp2_df = temp_df.rename(columns={\"D2\": rxn_num})\n",
    "        # Delete rxn column\n",
    "        del temp2_df['Rxn']\n",
    "        # Merge temp dataframe into reaction dataframe\n",
    "        if j == 0: \n",
    "            rxn_data = temp2_df\n",
    "        else:\n",
    "            rxn_data = rxn_data.merge(temp2_df, on=[\"Fluence\"])\n",
    "        \n",
    "        j += 1\n",
    "        \n",
    "    #Drop all reactions that contribute less than 5% to the rate at all times\n",
    "    k=0        \n",
    "    while k < len(plot_rxn_list):\n",
    "        if ((abs(rxn_data[plot_rxn_list[k]]) < 5).all()) :\n",
    "            #print('Reaction', plot_rxn_list[k], 'never contributes more than 5% to the rate.')\n",
    "            rxn_data.drop(plot_rxn_list[k] , inplace=True, axis=1)\n",
    "#         else :\n",
    "#             # Use the else bit if you want only the low contributing reactions\n",
    "#             rxn_data.drop(plot_rxn_list[k] , inplace=True, axis=1)\n",
    "        k += 1\n",
    "        \n",
    "    #print(plot_rxn_list)\n",
    "    rxn_data.to_pickle(version + '/pickle_dataframes/' + ana_list[i]+'_rxn_dataframe.pkl')\n",
    "    print(ana_list[i])\n",
    "    print(rxn_data.head(n=5))\n",
    "    i += 1\n",
    "    \n",
    "#rxn_data\n",
    "#print(plot_rxn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0e35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
